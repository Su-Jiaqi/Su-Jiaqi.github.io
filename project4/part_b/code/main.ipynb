{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "from numba import jit\n",
    "import time\n",
    "\n",
    "# Constants\n",
    "ransac_max_dist = 2  # RANSAC distance threshold\n",
    "n = 12  # Number of points to calculate the homography\n",
    "\n",
    "# Paths\n",
    "cwd = os.path.dirname(os.path.abspath(__file__))  # Current script path\n",
    "figures_path = os.path.join(cwd, 'figures')\n",
    "img_to_warp_path = os.path.join(figures_path, '1.jpg')\n",
    "img_base_path = os.path.join(figures_path, '2.jpg')\n",
    "src_pts_file = os.path.join(cwd, 'src_pts.npy')\n",
    "dst_pts_file = os.path.join(cwd, 'dst_pts.npy')\n",
    "\n",
    "def load_images():\n",
    "    \"\"\"Load images from the specified paths.\"\"\"\n",
    "    print(\"Loading images...\")\n",
    "    img_base = cv2.imread(img_base_path, 0)  # Base gray image\n",
    "    img_to_warp = cv2.imread(img_to_warp_path, 0)  # Image to be warped\n",
    "    img_base_rgb = cv2.cvtColor(cv2.imread(img_base_path, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)\n",
    "    img_to_warp_rgb = cv2.cvtColor(cv2.imread(img_to_warp_path, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)\n",
    "    print(\"Images loaded successfully.\")\n",
    "    return img_base, img_to_warp, img_base_rgb, img_to_warp_rgb\n",
    "\n",
    "def select_corresponding_points(image1, image2, num_points):\n",
    "    \"\"\"Manually select corresponding points from two images using mouse clicks.\"\"\"\n",
    "    print(f\"Manually selecting {num_points} corresponding points...\")\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax1, ax2 = axes\n",
    "    ax1.imshow(image1)\n",
    "    ax1.set_title(\"Image 1\")\n",
    "    ax1.axis('on')\n",
    "    \n",
    "    ax2.imshow(image2)\n",
    "    ax2.set_title(\"Image 2\")\n",
    "    ax2.axis('on')\n",
    "    \n",
    "    points1 = []\n",
    "    points2 = []\n",
    "\n",
    "    def onclick(event):\n",
    "        if event.inaxes == ax1 and len(points1) < num_points:  # If click on Image 1\n",
    "            points1.append([event.xdata, event.ydata])\n",
    "            print(f\"Point on Image 1: {event.xdata}, {event.ydata}\")\n",
    "            ax1.plot(event.xdata, event.ydata, 'ro')\n",
    "            fig.canvas.draw()\n",
    "        elif event.inaxes == ax2 and len(points2) < num_points:  # If click on Image 2\n",
    "            points2.append([event.xdata, event.ydata])\n",
    "            print(f\"Point on Image 2: {event.xdata}, {event.ydata}\")\n",
    "            ax2.plot(event.xdata, event.ydata, 'ro')\n",
    "            fig.canvas.draw()\n",
    "        \n",
    "        if len(points1) == num_points and len(points2) == num_points:\n",
    "            plt.close()\n",
    "\n",
    "    fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Point selection complete.\")\n",
    "    return np.array(points1, dtype=np.float32), np.array(points2, dtype=np.float32)\n",
    "\n",
    "def draw_correspondences(image1, image2, points1, points2):\n",
    "    # Create a combined image to display both images side by side\n",
    "    combined_width = image1.shape[1] + image2.shape[1]\n",
    "    combined_height = max(image1.shape[0], image2.shape[0])\n",
    "    combined_image = np.zeros((combined_height, combined_width, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Place the two images side by side\n",
    "    combined_image[:image1.shape[0], :image1.shape[1]] = image1\n",
    "    combined_image[:image2.shape[0], image1.shape[1]:] = image2\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.imshow(combined_image)\n",
    "    ax.set_title(\"Corresponding Points with Lines\")\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Draw the points\n",
    "    for p1, p2 in zip(points1, points2):\n",
    "        # Draw points on image 1\n",
    "        ax.plot(p1[0], p1[1], 'ro')\n",
    "        # Draw points on image 2 (shifted by image1's width)\n",
    "        ax.plot(p2[0] + image1.shape[1], p2[1], 'ro')\n",
    "        \n",
    "        # Draw a line connecting the corresponding points\n",
    "        line = plt.Line2D([p1[0], p2[0] + image1.shape[1]], [p1[1], p2[1]], color='blue')\n",
    "        ax.add_line(line)\n",
    "        \n",
    "    # Save the combined image with correspondences\n",
    "    correspondence_image_path = os.path.join(figures_path, 'correspondences.jpg')\n",
    "    fig.savefig(correspondence_image_path)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def calculate_homography(src_pts, dst_pts):\n",
    "    \"\"\"Calculate the homography matrix manually without using cv2.findHomography.\"\"\"\n",
    "    print(\"Calculating homography...\")\n",
    "    A = []\n",
    "    \n",
    "    for i in range(len(src_pts)):\n",
    "        x, y = src_pts[i][0], src_pts[i][1]\n",
    "        x_prime, y_prime = dst_pts[i][0], dst_pts[i][1]\n",
    "        \n",
    "        # Add equations for this pair of points\n",
    "        A.append([x, y, 1, 0, 0, 0, -x * x_prime, -y * x_prime, -x_prime])\n",
    "        A.append([0, 0, 0, x, y, 1, -x * y_prime, -y * y_prime, -y_prime])\n",
    "    \n",
    "    # Convert A to a numpy array and use SVD to solve for H\n",
    "    A = np.array(A)\n",
    "    U, S, Vt = np.linalg.svd(A)\n",
    "    H = Vt[-1].reshape(3, 3)\n",
    "    \n",
    "    # Normalize so that H[2,2] is 1\n",
    "    H = H / H[2, 2]\n",
    "    print(\"Homography calculated.\")\n",
    "    return np.linalg.inv(H)\n",
    "\n",
    "def compute_canvas_size(H, img_base_shape):\n",
    "    \"\"\"Compute the canvas size needed to contain both images.\"\"\"\n",
    "    print(\"Computing canvas size...\")\n",
    "    (y, x) = img_base_shape\n",
    "    pts = [\n",
    "        np.array([0, 0, 1], dtype=np.float32),  # Top-left\n",
    "        np.array([x, 0, 1], dtype=np.float32),  # Top-right\n",
    "        np.array([0, y, 1], dtype=np.float32),  # Bottom-left\n",
    "        np.array([x, y, 1], dtype=np.float32)   # Bottom-right\n",
    "    ]\n",
    "    \n",
    "    min_x, min_y, max_x, max_y = None, None, None, None\n",
    "    \n",
    "    for pt in pts:\n",
    "        hp = H @ pt\n",
    "        hp /= hp[2]  # Normalize\n",
    "        x, y = hp[0], hp[1]\n",
    "        min_x = min(min_x, x) if min_x is not None else x\n",
    "        min_y = min(min_y, y) if min_y is not None else y\n",
    "        max_x = max(max_x, x) if max_x is not None else x\n",
    "        max_y = max(max_y, y) if max_y is not None else y\n",
    "    \n",
    "    min_x, min_y = min(0, min_x), min(0, min_y)\n",
    "    max_x, max_y = max(max_x, img_base_shape[1]), max(max_y, img_base_shape[0])\n",
    "    \n",
    "    T = np.identity(3, dtype=np.float32)\n",
    "    if min_x < 0:\n",
    "        T[0, 2] = -min_x\n",
    "    if min_y < 0:\n",
    "        T[1, 2] = -min_y\n",
    "    \n",
    "    print(\"Canvas size computed.\")\n",
    "    return T, int(math.ceil(max_x - min_x)), int(math.ceil(max_y - min_y))\n",
    "\n",
    "@jit(nopython=True)\n",
    "def warp_pixel(src_x, src_y, img):\n",
    "    if 0 <= src_x < img.shape[1] - 1 and 0 <= src_y < img.shape[0] - 1:\n",
    "        x0, y0 = int(src_x), int(src_y)\n",
    "        x1, y1 = x0 + 1, y0 + 1\n",
    "        \n",
    "        wa = (x1 - src_x) * (y1 - src_y)\n",
    "        wb = (src_x - x0) * (y1 - src_y)\n",
    "        wc = (x1 - src_x) * (src_y - y0)\n",
    "        wd = (src_x - x0) * (src_y - y0)\n",
    "        \n",
    "        return (wa * img[y0, x0] + wb * img[y0, x1] + \n",
    "                wc * img[y1, x0] + wd * img[y1, x1]).astype(np.uint8)\n",
    "    return np.zeros(3, dtype=np.uint8)\n",
    "\n",
    "def manual_warp_perspective(img, M, output_size):\n",
    "    height, width = output_size[::-1]\n",
    "    warped_img = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    \n",
    "    M_inv = np.linalg.inv(M)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for y in range(height):\n",
    "        if y % 100 == 0:\n",
    "            print(f\"Processing row {y}/{height}, Time elapsed: {time.time() - start_time:.2f}s\")\n",
    "        for x in range(width):\n",
    "            src = M_inv.dot([x, y, 1])\n",
    "            src = src[:2] / src[2]\n",
    "            warped_img[y, x] = warp_pixel(src[0], src[1], img)\n",
    "    \n",
    "    return warped_img\n",
    "\n",
    "def warp_images(img_base_rgb, img_to_warp_rgb, H, T, img_w, img_h):\n",
    "    print(\"Warping base image...\")\n",
    "    img_base_translated = manual_warp_perspective(img_base_rgb, T, (img_w, img_h))\n",
    "    print(\"Base image warped.\")\n",
    "    \n",
    "    base_translated_image_path = os.path.join(figures_path, 'base_translated_image.jpg')\n",
    "    cv2.imwrite(base_translated_image_path, cv2.cvtColor(img_base_translated, cv2.COLOR_BGR2RGB))\n",
    "    plt.figure()\n",
    "    plt.imshow(img_base_translated)\n",
    "    plt.title('Warped Base Image')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Warping second image...\")\n",
    "    M_inv = T @ H\n",
    "    warped_img = manual_warp_perspective(img_to_warp_rgb, M_inv, (img_w, img_h))\n",
    "    print(\"Second image warped.\")\n",
    "    \n",
    "    warped_image_path = os.path.join(figures_path, 'warped_image.jpg')\n",
    "    cv2.imwrite(warped_image_path, cv2.cvtColor(warped_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.figure()\n",
    "    plt.imshow(warped_img)\n",
    "    plt.title('Warped Image to Be Mapped')\n",
    "    plt.show()\n",
    " \n",
    "    return img_base_translated, warped_img\n",
    "\n",
    "def rectify_image(image, pts_source):\n",
    "    # 根据选择的点自动计算目标矩形\n",
    "    width_top = np.linalg.norm(pts_source[0] - pts_source[1])\n",
    "    width_bottom = np.linalg.norm(pts_source[2] - pts_source[3])\n",
    "    width = max(int(width_top), int(width_bottom))\n",
    "\n",
    "    height_left = np.linalg.norm(pts_source[0] - pts_source[2])\n",
    "    height_right = np.linalg.norm(pts_source[1] - pts_source[3])\n",
    "    height = max(int(height_left), int(height_right))\n",
    "    \n",
    "    # 自动生成 \"横平竖直\" 的目标矩形\n",
    "    pts_rectified = np.array([\n",
    "        [0, 0], \n",
    "        [width - 1, 0], \n",
    "        [width - 1, height - 1], \n",
    "        [0, height - 1]\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    # 计算单应性矩阵\n",
    "    H = calculate_homography(pts_source, pts_rectified)\n",
    "    rectified = warp_images(image, H)\n",
    "    return rectified\n",
    "\n",
    "def blend_images(img_base_translated, warped_img):\n",
    "    \"\"\"Blend the two images together using masking.\"\"\"\n",
    "    canvas = np.zeros_like(img_base_translated)\n",
    "    _, mask = cv2.threshold(warped_img, 0, 255, cv2.THRESH_BINARY_INV)\n",
    "    pre_final_img = cv2.add(canvas, img_base_translated, mask=mask[:, :, 0], dtype=cv2.CV_8U)\n",
    "    return cv2.add(pre_final_img, warped_img, dtype=cv2.CV_8U)\n",
    "\n",
    "def save_and_show_result(img_final):\n",
    "    \"\"\"Save and display the resulting blended image.\"\"\"\n",
    "    plt.figure()\n",
    "    plt.imshow(img_final)\n",
    "    plt.title('Result')\n",
    "    result_path = os.path.join(figures_path, 'result.jpg')\n",
    "    cv2.imwrite(result_path, cv2.cvtColor(img_final, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    # Step 1: Load images\n",
    "    print(\"Step 1: Load images.\")\n",
    "    img_base, img_to_warp, img_base_rgb, img_to_warp_rgb = load_images()\n",
    "    \n",
    "    # Step 2: Manually select corresponding points if not already saved\n",
    "    print(\"Step 2: Select corresponding points or load from file.\")\n",
    "    if not os.path.exists(src_pts_file) or not os.path.exists(dst_pts_file):\n",
    "        print(f\"Please select {n} corresponding points between Image 1 and Image 2...\")\n",
    "        src_pts, dst_pts = select_corresponding_points(img_base_rgb, img_to_warp_rgb, n)\n",
    "        # Save the points to file for future use\n",
    "        np.save(src_pts_file, src_pts)\n",
    "        np.save(dst_pts_file, dst_pts)\n",
    "        print(\"Points saved to file.\")\n",
    "    else:\n",
    "        # Load previously saved points\n",
    "        src_pts = np.load(src_pts_file)\n",
    "        dst_pts = np.load(dst_pts_file)\n",
    "        print(\"Loaded saved points.\")\n",
    "\n",
    "    # Step 3: Calculate homography\n",
    "    print(\"Step 3: Calculate homography.\")\n",
    "    H = calculate_homography(src_pts, dst_pts)\n",
    "    \n",
    "    # 显示对应点并保存图片\n",
    "    print(\"Drawing and saving correspondence image.\")\n",
    "    draw_correspondences(img_base_rgb, img_to_warp_rgb, src_pts, dst_pts)\n",
    "    \n",
    "    # Step 4: Compute canvas size\n",
    "    print(\"Step 4: Compute canvas size.\")\n",
    "    T, img_w, img_h = compute_canvas_size(H, img_base.shape)\n",
    "    \n",
    "    # Step 5: Warp images\n",
    "    print(\"Step 5: Warp images.\")\n",
    "    img_base_translated, warped_img = warp_images(img_base_rgb, img_to_warp_rgb, H, T, img_w, img_h)\n",
    "    \n",
    "    # Step 6: Blend images\n",
    "    print(\"Step 6: Blend images.\")\n",
    "    img_final = blend_images(img_base_translated, warped_img)\n",
    "    \n",
    "    # Step 7: Save and display result\n",
    "    print(\"Step 7: Save and display result.\")\n",
    "    save_and_show_result(img_final)\n",
    "    print(\"Processing completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "from numba import jit\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import corner_harris, peak_local_max\n",
    "\n",
    "# Constants\n",
    "ransac_max_dist = 2  # RANSAC distance threshold\n",
    "n = 12  # Number of points to calculate the homography\n",
    "\n",
    "# Paths\n",
    "cwd = os.path.dirname(os.path.abspath(__file__))  # Current script path\n",
    "figures_path = os.path.join(cwd, 'result')\n",
    "img_path = os.path.join(cwd, 'figures')\n",
    "img_to_warp_path = os.path.join(img_path, '18.jpg')\n",
    "img_base_path = os.path.join(img_path, '19.jpg')\n",
    "src_pts_file = os.path.join(cwd, './result/18_points.txt')\n",
    "dst_pts_file = os.path.join(cwd, './result/19_points.txt')\n",
    "\n",
    "def get_harris_corners(im, edge_discard=20):\n",
    "    \"\"\"\n",
    "    This function takes a b&w image and an optional amount to discard\n",
    "    on the edge (default is 5 pixels), and finds all harris corners\n",
    "    in the image. Harris corners near the edge are discarded and the\n",
    "    coordinates of the remaining corners are returned. A 2d array (h)\n",
    "    containing the h value of every pixel is also returned.\n",
    "\n",
    "    h is the same shape as the original image, im.\n",
    "    coords is 2 x n (ys, xs).\n",
    "    \"\"\"\n",
    "\n",
    "    assert edge_discard >= 20\n",
    "\n",
    "    # find harris corners\n",
    "    h = corner_harris(im, method='eps', sigma=1)\n",
    "    coords = peak_local_max(h, min_distance=1)\n",
    "\n",
    "    # discard points on edge\n",
    "    edge = edge_discard  # pixels\n",
    "    mask = (coords[:, 0] > edge) & \\\n",
    "           (coords[:, 0] < im.shape[0] - edge) & \\\n",
    "           (coords[:, 1] > edge) & \\\n",
    "           (coords[:, 1] < im.shape[1] - edge)\n",
    "    coords = coords[mask].T\n",
    "    return h, coords\n",
    "\n",
    "def dist2(x, c):\n",
    "    \"\"\"\n",
    "    dist2  Calculates squared distance between two sets of points.\n",
    "\n",
    "    Description\n",
    "    D = DIST2(X, C) takes two matrices of vectors and calculates the\n",
    "    squared Euclidean distance between them.  Both matrices must be of\n",
    "    the same column dimension.  If X has M rows and N columns, and C has\n",
    "    L rows and N columns, then the result has M rows and L columns.  The\n",
    "    I, Jth entry is the  squared distance from the Ith row of X to the\n",
    "    Jth row of C.\n",
    "\n",
    "    Adapted from code by Christopher M Bishop and Ian T Nabney.\n",
    "    \"\"\"\n",
    "    \n",
    "    ndata, dimx = x.shape\n",
    "    ncenters, dimc = c.shape\n",
    "    if dimx != dimc:\n",
    "        raise ValueError('Data dimension does not match dimension of centers')\n",
    "\n",
    "    return (np.ones((ncenters, 1)) * np.sum((x**2).T, axis=0)).T + \\\n",
    "            np.ones((ndata, 1)) * np.sum((c**2).T, axis=0)    - \\\n",
    "            2 * np.inner(x, c)\n",
    "\n",
    "# 绘制角点并保存彩色图像\n",
    "def plot_save_corners(image, corners, save_path):\n",
    "    # 绘制角点在彩色图像上\n",
    "    for y, x in zip(corners[0], corners[1]):\n",
    "        cv2.circle(image, (int(x), int(y)), 1, (0, 0, 255), -1)  # 使用红色点\n",
    "    \n",
    "    # 保存带有角点的图像\n",
    "    cv2.imwrite(save_path, image)\n",
    "    print(f\"保存成功：{save_path}\")\n",
    "\n",
    "# ANMS 实现，使用 dist2 函数计算距离\n",
    "def adaptive_non_maximal_suppression(corner_strength, corners, num_points=500, crobust=0.9):\n",
    "    # 存储 (y, x, 强度) 形式的兴趣点\n",
    "    interest_points = [(y, x, corner_strength[y, x]) for y, x in zip(corners[0], corners[1])]\n",
    "    # 按强度降序排序\n",
    "    interest_points = sorted(interest_points, key=lambda point: point[2], reverse=True)\n",
    "\n",
    "    # 将兴趣点坐标转换为数组，并按顺序保存\n",
    "    points = np.array([[y, x] for y, x, _ in interest_points])\n",
    "\n",
    "    # 计算兴趣点的抑制半径\n",
    "    radii = np.full(len(points), float('inf'))\n",
    "\n",
    "    # 依次计算抑制半径\n",
    "    for i in range(len(points)):\n",
    "        # 选择当前点及其所有强度更高的点，计算距离\n",
    "        current_point = points[i].reshape(1, -1)\n",
    "        stronger_points = points[:i]\n",
    "        \n",
    "        # 仅当存在强度更大的邻居时，才计算抑制半径\n",
    "        if stronger_points.size > 0:\n",
    "            # 计算当前点与所有更强点之间的距离\n",
    "            distances = np.sqrt(dist2(current_point, stronger_points)).flatten()\n",
    "            radii[i] = distances.min()\n",
    "\n",
    "    # 按半径降序选择前 num_points 个兴趣点\n",
    "    selected_points = sorted(zip(radii, interest_points), key=lambda x: x[0], reverse=True)[:num_points]\n",
    "    selected_points = [(int(x), int(y)) for _, (x, y, _) in selected_points]\n",
    "    \n",
    "    return selected_points\n",
    "\n",
    "# 绘制角点并保存彩色图像\n",
    "def plot_and_save_corners(image, points, save_path):\n",
    "    # 绘制兴趣点在彩色图像上\n",
    "    for y, x in points:\n",
    "        cv2.circle(image, (x, y), 3, (0, 0, 255), -1)  # 使用红色点，半径 3\n",
    "    \n",
    "    # 保存带有兴趣点的图像\n",
    "    cv2.imwrite(save_path, image)\n",
    "    print(f\"保存成功：{save_path}\")\n",
    "\n",
    "# 特征描述符提取函数\n",
    "def extract_feature_descriptors(image, points, window_size=40, patch_size=8, spacing=5):\n",
    "    descriptors = []\n",
    "    half_window = window_size // 2\n",
    "\n",
    "    # 遍历每个兴趣点\n",
    "    for y, x in points:\n",
    "        # 提取中心点周围的 40x40 窗口，确保不超出边界\n",
    "        if (y - half_window < 0 or y + half_window >= image.shape[0] or \n",
    "            x - half_window < 0 or x + half_window >= image.shape[1]):\n",
    "            continue  # 跳过边界处的兴趣点\n",
    "\n",
    "        # 提取 40x40 的大窗口\n",
    "        window = image[y - half_window:y + half_window, x - half_window:x + half_window]\n",
    "\n",
    "        # 缩小采样，获得 8x8 的采样点\n",
    "        patch = cv2.resize(window, (patch_size, patch_size), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # 归一化：偏置-增益归一化，设均值为 0，标准差为 1\n",
    "        patch = (patch - np.mean(patch)) / (np.std(patch) + 1e-5)\n",
    "\n",
    "        # 将归一化后的描述符添加到列表\n",
    "        descriptors.append(patch.flatten())\n",
    "\n",
    "    return np.array(descriptors)\n",
    "\n",
    "# 特征匹配函数，添加调试信息\n",
    "def match_features(descriptors1, descriptors2, threshold=0.5):\n",
    "    matches = []\n",
    "    print(f\"匹配的阈值：{threshold}\\n\")\n",
    "    # print(\"匹配细节：\")\n",
    "\n",
    "    # 遍历 descriptors1 的每个描述符\n",
    "    for i, desc1 in enumerate(descriptors1):\n",
    "        # 计算当前描述符与 descriptors2 中所有描述符的距离\n",
    "        distances = np.linalg.norm(descriptors2 - desc1, axis=1)\n",
    "        \n",
    "        # 找到第一和第二最近邻的距离和索引\n",
    "        nearest_idx = np.argmin(distances)\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        second_nearest_idx = sorted_indices[1]\n",
    "        \n",
    "        # 计算误差比值\n",
    "        ratio = distances[nearest_idx] / distances[second_nearest_idx]\n",
    "\n",
    "        # 输出调试信息\n",
    "        # print(f\"描述符 {i} 与最近邻距离：{distances[nearest_idx]:.4f}, 次近邻距离：{distances[second_nearest_idx]:.4f}, 比值：{ratio:.4f}\")\n",
    "\n",
    "        # 应用 Lowe 的阈值筛选\n",
    "        if ratio < threshold:\n",
    "            matches.append((i, nearest_idx))\n",
    "            # print(f\"匹配成功：描述符 {i} -> {nearest_idx} (比值满足条件)\\n\")\n",
    "        # else:\n",
    "            # print(f\"匹配失败：描述符 {i} -> {nearest_idx} (比值不满足条件)\\n\")\n",
    "    \n",
    "    return matches\n",
    "\n",
    "def save_matched_points(anms_points1, anms_points2, matches, src_file=\"./result/19_points.txt\", dst_file=\"./result/18_points.txt\"):\n",
    "    # 根据 matches 中的对应关系，获取点的坐标，并反转 x 和 y 顺序\n",
    "    src_points = [(anms_points1[i][1], anms_points1[i][0]) for i, j in matches]  # 第一个图片的匹配点\n",
    "    dst_points = [(anms_points2[j][1], anms_points2[j][0]) for i, j in matches]  # 第二个图片的匹配点\n",
    "\n",
    "    # 保存源点和目标点到对应的 txt 文件\n",
    "    np.savetxt(src_file, src_points, fmt=\"%.4f\", comments=\"\")\n",
    "    np.savetxt(dst_file, dst_points, fmt=\"%.4f\", comments=\"\")\n",
    "\n",
    "    print(f\"匹配的源点保存在 {src_file}\")\n",
    "    print(f\"匹配的目标点保存在 {dst_file}\")\n",
    "\n",
    "# 绘制匹配的点对\n",
    "def plot_and_save_matched_points(image1, src_points, image2, dst_points, save_path):\n",
    "    # 创建一个新图像以并排显示两张图片\n",
    "    combined_width = image1.shape[1] + image2.shape[1]\n",
    "    combined_height = max(image1.shape[0], image2.shape[0])\n",
    "    new_image = np.zeros((combined_height, combined_width, 3), dtype=np.uint8)\n",
    "    \n",
    "    # 确保图像是三通道\n",
    "    if len(image1.shape) == 2:  # 如果 image1 是单通道灰度图像\n",
    "        image1 = cv2.cvtColor(image1, cv2.COLOR_GRAY2BGR)\n",
    "    if len(image2.shape) == 2:  # 如果 image2 是单通道灰度图像\n",
    "        image2 = cv2.cvtColor(image2, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # 将两张图像放到一起\n",
    "    new_image[:image1.shape[0], :image1.shape[1]] = image1\n",
    "    new_image[:image2.shape[0], image1.shape[1]:] = image2\n",
    "    \n",
    "    # 绘制匹配的点对\n",
    "    for (x1, y1), (x2, y2) in zip(src_points, dst_points):\n",
    "        x1, y1 = int(x1), int(y1)\n",
    "        x2, y2 = int(x2) + image1.shape[1], int(y2)  # 将第二张图像的坐标向右平移\n",
    "\n",
    "        # 画点和连线\n",
    "        cv2.circle(new_image, (x1, y1), 3, (0, 0, 255), -1)\n",
    "        cv2.circle(new_image, (x2, y2), 3, (0, 0, 255), -1)\n",
    "        cv2.line(new_image, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "\n",
    "    # 保存图像\n",
    "    cv2.imwrite(save_path, new_image)\n",
    "    print(f\"匹配点图像已保存到: {save_path}\")\n",
    "\n",
    "def load_images():\n",
    "    \"\"\"Load images from the specified paths.\"\"\"\n",
    "    print(\"Loading images...\")\n",
    "    img_base = cv2.imread(img_base_path, 0)  # Base gray image\n",
    "    img_to_warp = cv2.imread(img_to_warp_path, 0)  # Image to be warped\n",
    "    img_base_rgb = cv2.cvtColor(cv2.imread(img_base_path, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)\n",
    "    img_to_warp_rgb = cv2.cvtColor(cv2.imread(img_to_warp_path, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)\n",
    "    print(\"Images loaded successfully.\")\n",
    "    return img_base, img_to_warp, img_base_rgb, img_to_warp_rgb\n",
    "\n",
    "def select_corresponding_points(image1, image2, num_points):\n",
    "    \"\"\"Manually select corresponding points from two images using mouse clicks.\"\"\"\n",
    "    print(f\"Manually selecting {num_points} corresponding points...\")\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax1, ax2 = axes\n",
    "    ax1.imshow(image1)\n",
    "    ax1.set_title(\"Image 1\")\n",
    "    ax1.axis('on')\n",
    "    \n",
    "    ax2.imshow(image2)\n",
    "    ax2.set_title(\"Image 2\")\n",
    "    ax2.axis('on')\n",
    "    \n",
    "    points1 = []\n",
    "    points2 = []\n",
    "\n",
    "    def onclick(event):\n",
    "        if event.inaxes == ax1 and len(points1) < num_points:  # If click on Image 1\n",
    "            points1.append([event.xdata, event.ydata])\n",
    "            print(f\"Point on Image 1: {event.xdata}, {event.ydata}\")\n",
    "            ax1.plot(event.xdata, event.ydata, 'ro')\n",
    "            fig.canvas.draw()\n",
    "        elif event.inaxes == ax2 and len(points2) < num_points:  # If click on Image 2\n",
    "            points2.append([event.xdata, event.ydata])\n",
    "            print(f\"Point on Image 2: {event.xdata}, {event.ydata}\")\n",
    "            ax2.plot(event.xdata, event.ydata, 'ro')\n",
    "            fig.canvas.draw()\n",
    "        \n",
    "        if len(points1) == num_points and len(points2) == num_points:\n",
    "            plt.close()\n",
    "\n",
    "    fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Point selection complete.\")\n",
    "    return np.array(points1, dtype=np.float32), np.array(points2, dtype=np.float32)\n",
    "\n",
    "def draw_correspondences(image1, image2, points1, points2):\n",
    "    # Create a combined image to display both images side by side\n",
    "    combined_width = image1.shape[1] + image2.shape[1]\n",
    "    combined_height = max(image1.shape[0], image2.shape[0])\n",
    "    combined_image = np.zeros((combined_height, combined_width, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Place the two images side by side\n",
    "    combined_image[:image1.shape[0], :image1.shape[1]] = image1\n",
    "    combined_image[:image2.shape[0], image1.shape[1]:] = image2\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.imshow(combined_image)\n",
    "    ax.set_title(\"Corresponding Points with Lines\")\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Draw the points\n",
    "    for p1, p2 in zip(points1, points2):\n",
    "        # Draw points on image 1\n",
    "        ax.plot(p1[0], p1[1], 'ro')\n",
    "        # Draw points on image 2 (shifted by image1's width)\n",
    "        ax.plot(p2[0] + image1.shape[1], p2[1], 'ro')\n",
    "        \n",
    "        # Draw a line connecting the corresponding points\n",
    "        line = plt.Line2D([p1[0], p2[0] + image1.shape[1]], [p1[1], p2[1]], color='blue')\n",
    "        ax.add_line(line)\n",
    "        \n",
    "    # Save the combined image with correspondences\n",
    "    correspondence_image_path = os.path.join(figures_path, 'correspondences.jpg')\n",
    "    fig.savefig(correspondence_image_path)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def calculate_homography(src_pts, dst_pts):\n",
    "    \"\"\"Calculate the homography matrix manually without using cv2.findHomography.\"\"\"\n",
    "    # print(\"Calculating homography...\")\n",
    "    A = []\n",
    "    \n",
    "    for i in range(len(src_pts)):\n",
    "        x, y = src_pts[i][0], src_pts[i][1]\n",
    "        x_prime, y_prime = dst_pts[i][0], dst_pts[i][1]\n",
    "        \n",
    "        # Add equations for this pair of points\n",
    "        A.append([x, y, 1, 0, 0, 0, -x * x_prime, -y * x_prime, -x_prime])\n",
    "        A.append([0, 0, 0, x, y, 1, -x * y_prime, -y * y_prime, -y_prime])\n",
    "    \n",
    "    # Convert A to a numpy array and use SVD to solve for H\n",
    "    A = np.array(A)\n",
    "    U, S, Vt = np.linalg.svd(A)\n",
    "    H = Vt[-1].reshape(3, 3)\n",
    "    \n",
    "    # Normalize so that H[2,2] is 1\n",
    "    H = H / H[2, 2]\n",
    "    # print(\"Homography calculated.\")\n",
    "    return H\n",
    "\n",
    "def ransac_homography(src_pts, dst_pts, num_iterations=5000, threshold=2.0, min_inliers=4,n=0):\n",
    "    \"\"\"RANSAC algorithm to find a robust homography matrix.\"\"\"\n",
    "    max_inliers = 0\n",
    "    best_H = None\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        # Step 1: 随机选择 4 对点\n",
    "        indices = random.sample(range(len(src_pts)), 4)\n",
    "        src_sample = src_pts[indices]\n",
    "        dst_sample = dst_pts[indices]\n",
    "\n",
    "        # Step 2: 计算单应性矩阵 H\n",
    "        try:\n",
    "            H = calculate_homography(src_sample, dst_sample)\n",
    "        except np.linalg.LinAlgError:\n",
    "            # 如果计算 H 失败（例如矩阵不可逆），跳过该次迭代\n",
    "            n += 1\n",
    "            continue\n",
    "        \n",
    "        # Step 3: 将 src_pts 投影到目标空间并计算误差\n",
    "        src_pts_homogeneous = np.hstack((src_pts, np.ones((len(src_pts), 1))))\n",
    "        projected_pts = (H @ src_pts_homogeneous.T).T\n",
    "        projected_pts /= projected_pts[:, 2].reshape(-1, 1)  # 归一化\n",
    "\n",
    "        # Step 4: 计算每个投影点与目标点之间的欧氏距离\n",
    "        distances = np.linalg.norm(projected_pts[:, :2] - dst_pts, axis=1)\n",
    "        \n",
    "        # Step 5: 计算内点数量\n",
    "        inliers = distances < threshold\n",
    "        num_inliers = np.sum(inliers)\n",
    "\n",
    "        # Step 6: 检查是否找到新的最佳模型\n",
    "        if num_inliers > max_inliers:\n",
    "            max_inliers = num_inliers\n",
    "            best_inliers_src = src_pts[inliers]\n",
    "            best_inliers_dst = dst_pts[inliers]\n",
    "            best_H = H\n",
    "            print(f\"Iteration {i+1}: Found new best with {num_inliers} inliers\")\n",
    "            \n",
    "    print(f\"Failed to calculate H {n} times.\")\n",
    "    # Step 7: 如果找到足够的内点，重新基于所有内点计算单应性矩阵\n",
    "    if max_inliers >= min_inliers:\n",
    "        best_H = calculate_homography(best_inliers_src, best_inliers_dst)\n",
    "        print(f\"RANSAC completed with {max_inliers} inliers.\")\n",
    "    else:\n",
    "        raise ValueError(\"RANSAC could not find a sufficient number of inliers.\")\n",
    "\n",
    "    return best_H\n",
    "\n",
    "def compute_canvas_size(H, img_base_shape):\n",
    "    \"\"\"Compute the canvas size needed to contain both images.\"\"\"\n",
    "    print(\"Computing canvas size...\")\n",
    "    (y, x) = img_base_shape\n",
    "    pts = [\n",
    "        np.array([0, 0, 1], dtype=np.float32),  # Top-left\n",
    "        np.array([x, 0, 1], dtype=np.float32),  # Top-right\n",
    "        np.array([0, y, 1], dtype=np.float32),  # Bottom-left\n",
    "        np.array([x, y, 1], dtype=np.float32)   # Bottom-right\n",
    "    ]\n",
    "    \n",
    "    min_x, min_y, max_x, max_y = None, None, None, None\n",
    "    \n",
    "    for pt in pts:\n",
    "        hp = np.linalg.inv(H) @ pt\n",
    "        hp /= hp[2]  # Normalize\n",
    "        x, y = hp[0], hp[1]\n",
    "        min_x = min(min_x, x) if min_x is not None else x\n",
    "        min_y = min(min_y, y) if min_y is not None else y\n",
    "        max_x = max(max_x, x) if max_x is not None else x\n",
    "        max_y = max(max_y, y) if max_y is not None else y\n",
    "    \n",
    "    min_x, min_y = min(0, min_x), min(0, min_y)\n",
    "    max_x, max_y = max(max_x, img_base_shape[1]), max(max_y, img_base_shape[0])\n",
    "    \n",
    "    T = np.identity(3, dtype=np.float32)\n",
    "    if min_x < 0:\n",
    "        T[0, 2] = -min_x\n",
    "    if min_y < 0:\n",
    "        T[1, 2] = -min_y\n",
    "    \n",
    "    print(\"Canvas size computed.\")\n",
    "    return T, int(math.ceil(max_x - min_x)), int(math.ceil(max_y - min_y))\n",
    "\n",
    "@jit(nopython=True)\n",
    "def warp_pixel(src_x, src_y, img):\n",
    "    if 0 <= src_x < img.shape[1] - 1 and 0 <= src_y < img.shape[0] - 1:\n",
    "        x0, y0 = int(src_x), int(src_y)\n",
    "        x1, y1 = x0 + 1, y0 + 1\n",
    "        \n",
    "        wa = (x1 - src_x) * (y1 - src_y)\n",
    "        wb = (src_x - x0) * (y1 - src_y)\n",
    "        wc = (x1 - src_x) * (src_y - y0)\n",
    "        wd = (src_x - x0) * (src_y - y0)\n",
    "        \n",
    "        return (wa * img[y0, x0] + wb * img[y0, x1] + \n",
    "                wc * img[y1, x0] + wd * img[y1, x1]).astype(np.uint8)\n",
    "    return np.zeros(3, dtype=np.uint8)\n",
    "\n",
    "def manual_warp_perspective(img, M, output_size):\n",
    "    height, width = output_size[::-1]\n",
    "    warped_img = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    \n",
    "    M_inv = np.linalg.inv(M)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for y in range(height):\n",
    "        if y % 100 == 0:\n",
    "            print(f\"Processing row {y}/{height}, Time elapsed: {time.time() - start_time:.2f}s\")\n",
    "        for x in range(width):\n",
    "            src = M_inv.dot([x, y, 1])\n",
    "            src = src[:2] / src[2]\n",
    "            warped_img[y, x] = warp_pixel(src[0], src[1], img)\n",
    "    \n",
    "    return warped_img\n",
    "\n",
    "def warp_images(img_base_rgb, img_to_warp_rgb, H, T, img_w, img_h):\n",
    "    print(\"Warping base image...\")\n",
    "    img_base_translated = manual_warp_perspective(img_base_rgb, T, (img_w, img_h))\n",
    "    print(\"Base image warped.\")\n",
    "    \n",
    "    base_translated_image_path = os.path.join(figures_path, 'base_translated_image.jpg')\n",
    "    cv2.imwrite(base_translated_image_path, cv2.cvtColor(img_base_translated, cv2.COLOR_BGR2RGB))\n",
    "    plt.figure()\n",
    "    plt.imshow(img_base_translated)\n",
    "    plt.title('Warped Base Image')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Warping second image...\")\n",
    "    M_inv = T @ np.linalg.inv(H)\n",
    "    warped_img = manual_warp_perspective(img_to_warp_rgb, M_inv, (img_w, img_h))\n",
    "    print(\"Second image warped.\")\n",
    "    \n",
    "    warped_image_path = os.path.join(figures_path, 'warped_image.jpg')\n",
    "    cv2.imwrite(warped_image_path, cv2.cvtColor(warped_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.figure()\n",
    "    plt.imshow(warped_img)\n",
    "    plt.title('Warped Image to Be Mapped')\n",
    "    plt.show()\n",
    " \n",
    "    return img_base_translated, warped_img\n",
    "\n",
    "def rectify_image(image, pts_source):\n",
    "    # 根据选择的点自动计算目标矩形\n",
    "    width_top = np.linalg.norm(pts_source[0] - pts_source[1])\n",
    "    width_bottom = np.linalg.norm(pts_source[2] - pts_source[3])\n",
    "    width = max(int(width_top), int(width_bottom))\n",
    "\n",
    "    height_left = np.linalg.norm(pts_source[0] - pts_source[2])\n",
    "    height_right = np.linalg.norm(pts_source[1] - pts_source[3])\n",
    "    height = max(int(height_left), int(height_right))\n",
    "    \n",
    "    # 自动生成 \"横平竖直\" 的目标矩形\n",
    "    pts_rectified = np.array([\n",
    "        [0, 0], \n",
    "        [width - 1, 0], \n",
    "        [width - 1, height - 1], \n",
    "        [0, height - 1]\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    # 计算单应性矩阵\n",
    "    H = calculate_homography(pts_source, pts_rectified)\n",
    "    rectified = warp_images(image, H)\n",
    "    return rectified\n",
    "\n",
    "def blend_images(img_base_translated, warped_img):\n",
    "    \"\"\"Blend the two images together using masking.\"\"\"\n",
    "    canvas = np.zeros_like(img_base_translated)\n",
    "    _, mask = cv2.threshold(warped_img, 0, 255, cv2.THRESH_BINARY_INV)\n",
    "    pre_final_img = cv2.add(canvas, img_base_translated, mask=mask[:, :, 0], dtype=cv2.CV_8U)\n",
    "    return cv2.add(pre_final_img, warped_img, dtype=cv2.CV_8U)\n",
    "\n",
    "def save_and_show_result(img_final):\n",
    "    \"\"\"Save and display the resulting blended image.\"\"\"\n",
    "    plt.figure()\n",
    "    plt.imshow(img_final)\n",
    "    plt.title('Result')\n",
    "    result_path = os.path.join(figures_path, 'result.jpg')\n",
    "    cv2.imwrite(result_path, cv2.cvtColor(img_final, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "\n",
    "def main():    \n",
    "    # 加载彩色图像并转换为灰度\n",
    "    image1 = cv2.imread(\"./figures/18.jpg\")\n",
    "    gray_image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    image2 = cv2.imread(\"./figures/19.jpg\")\n",
    "    gray_image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 检测角点并使用 ANMS 选择兴趣点\n",
    "    corner_strength1, corners1 = get_harris_corners(gray_image1, edge_discard=20)\n",
    "    # 显示图像并保存\n",
    "    # plot_save_corners(image1, corners1, \"result/18_corners.jpg\")\n",
    "    anms_points1 = adaptive_non_maximal_suppression(corner_strength1, corners1, num_points=500)\n",
    "    \n",
    "    corner_strength2, corners2 = get_harris_corners(gray_image2, edge_discard=20)\n",
    "    # 显示图像并保存\n",
    "    # plot_save_corners(image2, corners2, \"result/19_corners.jpg\")\n",
    "    anms_points2 = adaptive_non_maximal_suppression(corner_strength2, corners2, num_points=500)\n",
    "\n",
    "    # 显示图像并保存带有 ANMS 的兴趣点\n",
    "    plot_and_save_corners(image1, anms_points1, \"result/18_corners_anms.jpg\")\n",
    "    plot_and_save_corners(image2, anms_points2, \"result/19_corners_anms.jpg\")\n",
    "    \n",
    "    # 提取特征描述符\n",
    "    descriptors1 = extract_feature_descriptors(gray_image1, anms_points1)\n",
    "    descriptors2 = extract_feature_descriptors(gray_image2, anms_points2)\n",
    "\n",
    "    # 匹配特征点\n",
    "    matches = match_features(descriptors1, descriptors2)\n",
    "\n",
    "    # 输出匹配结果\n",
    "    print(f\"找到 {len(matches)} 对匹配点。\")\n",
    "    \n",
    "    # 保存匹配的点到txt文件\n",
    "    save_matched_points(anms_points1, anms_points2, matches)\n",
    "\n",
    "    # 读取matches_src_points.txt和matches_dst_points.txt文件，绘制匹配的点对\n",
    "    src_points = np.loadtxt(\"./result/18_points.txt\")\n",
    "    dst_points = np.loadtxt(\"./result/19_points.txt\")\n",
    "\n",
    "    # 显示匹配的点对\n",
    "    plot_and_save_matched_points(image1, src_points, image2, dst_points, \"result/18_19_matched_points.jpg\")\n",
    "    \n",
    "    # Step 1: Load images\n",
    "    print(\"Step 1: Load images.\")\n",
    "    img_base, img_to_warp, img_base_rgb, img_to_warp_rgb = load_images()\n",
    "    \n",
    "    # Step 2: Load corresponding points from txt files\n",
    "    print(\"Step 2: Load corresponding points from txt files.\")\n",
    "    if os.path.exists(src_pts_file) and os.path.exists(dst_pts_file):\n",
    "        src_pts = np.loadtxt(src_pts_file)\n",
    "        dst_pts = np.loadtxt(dst_pts_file)\n",
    "        print(\"Loaded saved points from txt files.\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Source or destination points file not found. Please create '12_points.txt' and '13_points.txt' with corresponding points.\")\n",
    "\n",
    "    # Step 3: Calculate homography\n",
    "    print(\"Step 3: Calculate homography.\")\n",
    "    # H = calculate_homography(src_pts, dst_pts)\n",
    "    H = ransac_homography(src_pts, dst_pts)\n",
    "    print(\"Homography matrix:\")\n",
    "    print(H)\n",
    "    \n",
    "    # Display correspondences and save image\n",
    "    print(\"Drawing and saving correspondence image.\")\n",
    "    draw_correspondences(img_base_rgb, img_to_warp_rgb, src_pts, dst_pts)\n",
    "    \n",
    "    # Step 4: Compute canvas size\n",
    "    print(\"Step 4: Compute canvas size.\")\n",
    "    T, img_w, img_h = compute_canvas_size(H, img_base.shape)\n",
    "    \n",
    "    # Step 5: Warp images\n",
    "    print(\"Step 5: Warp images.\")\n",
    "    img_base_translated, warped_img = warp_images(img_base_rgb, img_to_warp_rgb, H, T, img_w, img_h)\n",
    "    \n",
    "    # 将img_base_translated 和 warped_img 取最大的大小，reisze,空出的部分用padding补齐\n",
    "    h1,w1 = img_base_translated.shape[:2]\n",
    "    h2,w2 = warped_img.shape[:2]\n",
    "    nWidth = max(w1,w2)\n",
    "    nHeight = max(h1,h2)\n",
    "    img_base_translated = cv2.resize(img_base_translated,(nWidth,nHeight))\n",
    "    warped_img = cv2.resize(warped_img,(nWidth,nHeight))\n",
    "    \n",
    "    # Step 6: Blend images\n",
    "    print(\"Step 6: Blend images.\")\n",
    "    img_final = blend_images(img_base_translated, warped_img)\n",
    "    \n",
    "    # Step 7: Save and display result\n",
    "    print(\"Step 7: Save and display result.\")\n",
    "    save_and_show_result(img_final)\n",
    "    print(\"Processing completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
